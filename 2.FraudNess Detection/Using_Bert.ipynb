{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers torch torchtext scikit-learn pandas\n",
    "%pip install torch==2.0.1 torchtext==0.15.2\n",
    "!pip install tensorflow\n",
    "%pip install transformers torch scikit-learn\n",
    "!pip install datasets\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "sentences = [\n",
    "    \"I received a call from someone asking for my bank account details.\",  # fraud\n",
    "    \"You've won a lottery! Send us your bank details to claim the prize.\",  # fraud\n",
    "    \"Please update your account information to prevent deactivation.\",  # fraud\n",
    "    \"Hey, just wanted to check in on our meeting next week.\",  # not fraud\n",
    "    \"I need help with my order; it didn't arrive on time.\",  # not fraud\n",
    "    \"Your account has been compromised; please send your password to fix it.\",  # fraud\n",
    "    \"Urgent: Your bank account is under review. Kindly verify your personal information immediately to avoid restrictions.\",  # fraud\n",
    "    \"Warning: Unauthorized login attempts detected on your account. Please confirm your identity to secure your account.\",  # fraud\n",
    "    \"We noticed suspicious activity in your account. Please reply with your account number to verify your identity.\",  # fraud\n",
    "    \"You have been selected to receive a special reward. Please send your payment details to claim your prize.\",  # fraud\n",
    "    \"Your subscription is about to expire. To prevent service interruption, please update your payment information as soon as possible.\",  # not fraud\n",
    "    \"Important: Your account has been locked due to multiple failed login attempts. Click here to reset your password.\",  # fraud\n",
    "    \"We are conducting a security check. Kindly provide your social security number and date of birth to verify your account.\",  # fraud\n",
    "    \"Exclusive Offer: You've won a free vacation! Please provide your payment details to confirm your booking.\",  # fraud\n",
    "    \"We need to verify your identity. Please send a copy of your ID and recent utility bill to proceed.\",  # fraud\n",
    "    \"Congratulations! You've won a gift card worth $500. Please reply with your email address and payment info to claim it.\",  # fraud\n",
    "    \"Immediate action required: Your account has been flagged for suspicious activity. Please log in and verify your account details immediately.\",  # fraud\n",
    "\n",
    "]\n",
    "\n",
    "labels = [1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,1,1,1,1]\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the input data\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=32)\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=32)\n",
    "\n",
    "# Create a Dataset object for the Hugging Face Trainer API\n",
    "train_dataset = Dataset.from_dict({'input_ids': train_encodings['input_ids'], 'attention_mask': train_encodings['attention_mask'], 'label': y_train})\n",
    "test_dataset = Dataset.from_dict({'input_ids': test_encodings['input_ids'], 'attention_mask': test_encodings['attention_mask'], 'label': y_test})\n",
    "\n",
    "# Load the pre-trained BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "\n",
    "\n",
    "# Define the compute_metrics function to calculate accuracy\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    # Convert numpy.ndarray to torch.Tensor\n",
    "    predictions = torch.tensor(predictions)\n",
    "    # Apply argmax to get the predicted labels\n",
    "    preds = torch.argmax(predictions, dim=-1)\n",
    "    return {'accuracy': accuracy_score(labels, preds)}\n",
    "\n",
    "\n",
    "# Define training arguments, disable wandb\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=10,              # number of training epochs\n",
    "    per_device_train_batch_size=4,   # batch size for training\n",
    "    per_device_eval_batch_size=4,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',\n",
    "    # learning_rate=5e-5,# directory for storing logs\n",
    "    report_to=\"none\",                # Disable Wandb\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=test_dataset,           # evaluation dataset\n",
    "    compute_metrics=compute_metrics      # pass the compute_metrics function\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "print(f\"Test Accuracy: {results['eval_accuracy']:.2f}\")\n",
    "\n",
    "# Test with a new sentence\n",
    "new_sentence = \"Hey, just wanted to check in on our meeting next week.\"\n",
    "inputs = tokenizer(new_sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=32)\n",
    "output = model(**inputs)\n",
    "prediction = torch.argmax(output.logits, dim=-1).item()\n",
    "print(f\"Fraud prediction for new sentence: {'fraud' if prediction == 1 else 'not fraud'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

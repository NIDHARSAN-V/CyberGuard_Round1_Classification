{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import pandas as pd \n",
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load your data \n",
    "# df = pd.read_csv(\"final_processed.csv\") \n",
    "df = pd.read_csv(\"sampled_data.csv\") \n",
    "\n",
    "# Drop rows with NaN values\n",
    "df = df.dropna()\n",
    "\n",
    "# Display the DataFrame to verify the data \n",
    "print(df.head()) \n",
    "\n",
    "# Map labels to integers \n",
    "label_to_int = {label: i for i, label in enumerate(df['sub_category'].unique())} \n",
    "df['sub_category'] = df['sub_category'].map(label_to_int) \n",
    "\n",
    "# Load the trained model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained(\"trained_bert_model\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"trained_bert_tokenizer\")\n",
    "\n",
    "# Ensure model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "\n",
    "int_to_label = {v: k for k, v in label_to_int.items()}\n",
    "\n",
    "# Define the prediction function\n",
    "def predict(model, tokenizer, texts, max_length=128):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            # Tokenize the input text\n",
    "            tokens = tokenizer(\n",
    "                text,\n",
    "                padding='max_length',\n",
    "                max_length=max_length,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            tokens = {key: val.to(model.device) for key, val in tokens.items()}\n",
    "            \n",
    "            # Get model outputs\n",
    "            output = model(**tokens)\n",
    "            _, predicted_class = torch.max(output.logits, dim=1)\n",
    "            predictions.append(predicted_class.item())\n",
    "    return predictions\n",
    "\n",
    "# Input texts to classify\n",
    "unknown_texts = [\n",
    "    \"received URL link for updating KYC from mobile no after opening received otp and entered and confirmation received saying KYC done like this received OTP till KYC after that started receiving sms from bank after sec delay on amount cut and then stopped further otp Bank is also responsible for delaying sms\",\n",
    "    \"some unknown user has send an email to my rwa and making my reputation at stake along with my family . i request you to please take a legal action and help me to find the person who has is ruing my personal reputation .\"\n",
    "]\n",
    "\n",
    "# Perform prediction\n",
    "predicted_classes = predict(model, tokenizer, unknown_texts)\n",
    "\n",
    "# Map predictions back to label names\n",
    "for text, prediction in zip(unknown_texts, predicted_classes):\n",
    "    predicted_label = int_to_label[prediction]\n",
    "    print(f\"Text: {text}\\nPredicted Class: {prediction} | Class Label: {predicted_label}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyber_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
